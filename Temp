 if (executor != null) {
                try {
                    Logger.info("Shutting down executor service...");
                    executor.shutdown(); // Disable new tasks from being submitted
                    
                    // Calculate dynamic timeout based on number of files queued
                    // Production-optimized: balances fast shutdown with safety for large batches
                    int filesQueued = totalFilesQueued.get();
                    long shutdownTimeout;
                    
                    if (filesQueued == 0) {
                        // No files processed - quick shutdown
                        shutdownTimeout = 5; // 5 seconds
                    } else if (filesQueued <= 10) {
                        // Small batch: 10 seconds per file + 30 second buffer
                        shutdownTimeout = (filesQueued * 10) + 30;
                    } else if (filesQueued <= 100) {
                        // Medium batch: 5 seconds per file + 2 minute buffer
                        shutdownTimeout = (filesQueued * 5) + 120;
                    } else {
                        // Large batch: 2 seconds per file + 5 minute buffer, max 8 hours
                        long calculated = (filesQueued * 2) + 300;
                        shutdownTimeout = Math.min(calculated, 28800); // 8 hours max
                    }
                    
                    Logger.info("Waiting for {} file(s) to complete (timeout: {} seconds / {}.{} minutes)...", 
                               filesQueued, shutdownTimeout, shutdownTimeout / 60, (shutdownTimeout % 60));
                    
                    long startTime = System.currentTimeMillis();
                    
                    // Wait for existing tasks to terminate
                    if (!executor.awaitTermination(shutdownTimeout, TimeUnit.SECONDS)) {
                        long waitedTime = (System.currentTimeMillis() - startTime) / 1000;
                        Logger.warn("Executor did not terminate after {} seconds, forcing shutdown...", waitedTime);
                        executor.shutdownNow(); // Cancel currently executing tasks
                        
                        // Wait a while for tasks to respond to being cancelled
                        if (!executor.awaitTermination(60, TimeUnit.SECONDS)) {
                            Logger.error("Executor did not terminate after forced shutdown");
                        }
                    } else {
                        long actualTime = (System.currentTimeMillis() - startTime) / 1000;
                        Logger.info("All tasks completed successfully in {} seconds", actualTime);
                    }
                    
                    Logger.info("Executor service shut down successfully");
                } catch (InterruptedException e) {
                    Logger.error("Interrupted while shutting down executor", e);
                    executor.shutdownNow();
                    Thread.currentThread().interrupt();
                }
            }



 /**
     * Process CSV file with row-level tracking
     */
    private ProcessingResult processCSVWithTracking(Path csvFilePath) throws IOException {
        ProcessingResult result = new ProcessingResult();
        String csvFileName = csvFilePath.getFileName().toString();
        
        // Prepare output files for success and failure tracking
        Path completedDir = Paths.get(basePath, Constants.COMPLETED_FOLDER);
        Path failedDir = Paths.get(basePath, Constants.FAILED_FOLDER);
        
        String baseFileName = csvFileName.replace(".csv", "");
        Path successFile = completedDir.resolve(baseFileName + "_SUCCESS.csv");
        Path failedFile = failedDir.resolve(baseFileName + "_FAILED.csv");
        
        List<String> successRows = new ArrayList<>();
        List<String> failedRows = new ArrayList<>();
        
        String skipHeaderProp = config.getProperty("app.skipHeaderRow");
        boolean skipHeaderRow = skipHeaderProp == null ? true : Boolean.parseBoolean(skipHeaderProp);
        String headerLine = null;
        
        // Get batch size from configuration
        String batchSizeStr = config.getProperty("db.batch.update.size");
        int batchSize = (batchSizeStr != null) ? Integer.parseInt(batchSizeStr) : 1000;
        
        logger.info("Processing CSV file: {}", csvFilePath);
        logger.info("Delimiter: pipe (|), Skip header: {}, Batch size: {}", skipHeaderRow, batchSize);
        
        Connection conn = null;
        try (BufferedReader reader = new BufferedReader(new FileReader(csvFilePath.toFile()))) {
            
            long connStartTime = System.currentTimeMillis();
            conn = connectionManager.getConnection();
            long connAcquireTime = System.currentTimeMillis() - connStartTime;
            logger.debug("Connection acquired in {} ms", connAcquireTime);
            
            String line;
            int rowNum = 0;
            
            // Read and process header
            if (skipHeaderRow && (line = reader.readLine()) != null) {
                headerLine = line.trim();
                logger.debug("Header: {}", headerLine);
            }
            
            // Build header index map
            Map<String, Integer> headerIndex = buildHeaderIndex(headerLine);
            
            // Validate required columns exist
            if (!validateRequiredColumns(headerIndex, csvFileName)) {
                result.failureCount = 1;
                // Close connection before returning
                if (conn != null) {
                    try {
                        conn.close();
                        logger.debug("Connection closed after validation failure");
                    } catch (SQLException e) {
                        logger.error("Error closing connection after validation failure", e);
                    }
                }
                return result;
            }
            
            // Batch processing buffers
            List<ClaimCenterDocumentDTO> batchDTOs = new ArrayList<>();
            List<String> batchLines = new ArrayList<>();
            
            // Process each row
            while ((line = reader.readLine()) != null) {
                rowNum++;
                
                // Skip empty lines
                if (line.trim().length() == 0) {
                    result.skippedEmptyLines++;
                    continue;
                }
                
                result.totalRows++;
                String currentLine = line;
                
                try {
                    // Parse CSV row
                    String[] cells = parseCSVLine(line);
                    
                    // Build DTO from CSV row
                    ClaimCenterDocumentDTO dto = buildDTOFromCSV(cells, headerIndex, csvFileName);
                    
                    dto.setDataMerged(true);
                    
                    // Validate DTO
                    validateDTO(dto, rowNum);
                    
                    // Add to batch
                    batchDTOs.add(dto);
                    batchLines.add(currentLine);
                    
                    // Process batch when it reaches batch size
                    if (batchDTOs.size() >= batchSize) {
                        processBatchWithFallback(batchDTOs, batchLines, conn, batchSize, 
                                               successRows, failedRows, result);
                        batchDTOs.clear();
                        batchLines.clear();
                        
                        logger.debug("Processed batch at row {}", rowNum);
                    }
                    
                } catch (Exception e) {
                    result.failureCount++;
                    String errorMsg = e.getMessage().replace("\"", "'").replace("|", ";");
                    failedRows.add(currentLine + "|" + errorMsg);
                    logger.error("Row {}: Failed to process - {}", rowNum, e.getMessage());
                }
            }
            
            // Process remaining batch
            if (!batchDTOs.isEmpty()) {
                processBatchWithFallback(batchDTOs, batchLines, conn, batchSize, 
                                       successRows, failedRows, result);
                logger.debug("Processed final batch of {} rows", batchDTOs.size());
            }
            
            // Commit all successful transactions
            conn.commit();
            logger.info("Transaction committed successfully");
            
            logger.info("CSV processing completed: Total={}, Success={}, Failed={}, Skipped Empty={}", 
                       result.totalRows, result.successCount, result.failureCount, result.skippedEmptyLines);
            
        } catch (SQLException e) {
            logger.error("Database error while processing CSV: {}", csvFileName, e);
            // Rollback on error
            if (conn != null) {
                try {
                    conn.rollback();
                    logger.warn("Transaction rolled back due to error");
                } catch (SQLException rollbackEx) {
                    logger.error("Error during rollback", rollbackEx);
                }
            }
            throw new IOException("Database error: " + e.getMessage(), e);
        } catch (Exception e) {
            logger.error("Unexpected error while processing CSV: {}", csvFileName, e);
            // Rollback on error
            if (conn != null) {
                try {
                    conn.rollback();
                    logger.warn("Transaction rolled back due to error");
                } catch (SQLException rollbackEx) {
                    logger.error("Error during rollback", rollbackEx);
                }
            }
            throw new IOException("Processing error: " + e.getMessage(), e);
        } finally {
            // Close connection
            if (conn != null) {
                try {
                    long closeStartTime = System.currentTimeMillis();
                    conn.close();
                    long closeTime = System.currentTimeMillis() - closeStartTime;
                    logger.debug("Connection closed and returned to pool in {} ms", closeTime);
                } catch (SQLException closeEx) {
                    logger.error("Error closing connection", closeEx);
                }
            }
        }
        
        // Write success file
        if (!successRows.isEmpty()) {
            writeSuccessFile(successFile, headerLine, successRows);
            logger.info("Created success file with {} rows: {}", successRows.size(), successFile);
        }
        
        // Write failed file (only if there are failures)
        if (!failedRows.isEmpty()) {
            writeFailedFile(failedFile, headerLine, failedRows);
            logger.info("Created failed file with {} rows: {}", failedRows.size(), failedFile);
        }
        
        return result;
    }
